# ğŸ—ï¸ System Architecture

## Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER                                â”‚
â”‚                    (Web Browser)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ HTTP Requests
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   FRONTEND                                  â”‚
â”‚                   (Next.js)                                 â”‚
â”‚                 Port: 3000                                  â”‚
â”‚                                                             â”‚
â”‚  Components:                                                â”‚
â”‚  â€¢ Dashboard Stats                                          â”‚
â”‚  â€¢ Scraping Controls                                        â”‚
â”‚  â€¢ Data Table                                               â”‚
â”‚  â€¢ Search/Filter                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ REST API Calls
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BACKEND                                  â”‚
â”‚                   (Flask API)                               â”‚
â”‚                  Port: 5000                                 â”‚
â”‚                                                             â”‚
â”‚  Endpoints:                                                 â”‚
â”‚  â€¢ GET  /api/announcements                                  â”‚
â”‚  â€¢ GET  /api/stats                                          â”‚
â”‚  â€¢ POST /api/scrape                                         â”‚
â”‚  â€¢ GET  /api/scrape/status                                  â”‚
â”‚  â€¢ PUT  /api/announcements/:id/check                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ SQL Queries
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   DATABASE                                  â”‚
â”‚                   (SQLite)                                  â”‚
â”‚              File: espaceagro.db                            â”‚
â”‚                                                             â”‚
â”‚  Table: announcements                                       â”‚
â”‚  â€¢ id (PRIMARY KEY)                                         â”‚
â”‚  â€¢ member_id (UNIQUE)                                       â”‚
â”‚  â€¢ announcement_title                                       â”‚
â”‚  â€¢ description                                              â”‚
â”‚  â€¢ products                                                 â”‚
â”‚  â€¢ location                                                 â”‚
â”‚  â€¢ announcement_url                                         â”‚
â”‚  â€¢ checked (0 or 1)                                         â”‚
â”‚  â€¢ created_at                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ Read/Write
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SCRAPER                                  â”‚
â”‚              (Python + Selenium)                            â”‚
â”‚                                                             â”‚
â”‚  Process:                                                   â”‚
â”‚  1. Connect to Chrome (debug mode)                          â”‚
â”‚  2. Navigate to espaceagro.com                              â”‚
â”‚  3. Extract announcement data                               â”‚
â”‚  4. Check for duplicates                                    â”‚
â”‚  5. Save new items to database                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ Remote Debugging Protocol
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CHROME                                   â”‚
â”‚              (Debug Mode: Port 9222)                        â”‚
â”‚                                                             â”‚
â”‚  â€¢ User logged in to espaceagro.com                         â”‚
â”‚  â€¢ Maintains session cookies                                â”‚
â”‚  â€¢ Controlled by Selenium                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Data Flow

### 1. User Starts Scraping

```
User clicks "Start Scraping"
    â†“
Frontend sends POST to /api/scrape
    â†“
Backend starts scraper in background thread
    â†“
Scraper connects to Chrome (port 9222)
    â†“
Scraper navigates to espaceagro.com
    â†“
Scraper extracts data from each page
    â†“
For each announcement:
    â†“
    Check if member_id exists in database
    â†“
    If NEW â†’ Insert into database
    â†“
    If EXISTS â†’ Skip
    â†“
Backend updates scraping status
    â†“
Frontend polls /api/scrape/status
    â†“
When complete, frontend refreshes data
    â†“
User sees updated table
```

### 2. User Checks Announcement

```
User clicks checkbox
    â†“
Frontend sends PUT to /api/announcements/:id/check
    â†“
Backend updates checked field in database
    â†“
Backend returns success
    â†“
Frontend updates UI (green background)
    â†“
Frontend refreshes stats
```

### 3. User Searches

```
User types in search box
    â†“
Frontend filters announcements locally
    â†“
Table updates in real-time
    â†“
(No backend call needed)
```

## Component Details

### Frontend (Next.js)

**File:** `frontend/app/page.tsx`

**State Management:**
```typescript
- announcements: Announcement[]
- stats: Stats
- loading: boolean
- scraping: boolean
- searchTerm: string
```

**Key Functions:**
```typescript
- fetchAnnouncements()  // Get all data
- fetchStats()          // Get statistics
- toggleCheck()         // Toggle checkbox
- startScraping()       // Start scraping
- filteredAnnouncements // Search filter
```

### Backend (Flask)

**File:** `api.py`

**Routes:**
```python
GET  /api/announcements        # Get all announcements
GET  /api/stats                # Get statistics
POST /api/scrape               # Start scraping
GET  /api/scrape/status        # Get scraping status
PUT  /api/announcements/:id/check  # Toggle checked
```

**Key Functions:**
```python
- get_db_connection()   # Database connection
- get_announcements()   # Query all records
- toggle_check()        # Update checked status
- start_scraping()      # Run scraper in thread
- get_stats()           # Calculate statistics
```

### Database (SQLite)

**File:** `espaceagro.db`

**Schema:**
```sql
CREATE TABLE announcements (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    member_id TEXT UNIQUE NOT NULL,
    company_name TEXT,
    announcement_title TEXT,
    description TEXT,
    products TEXT,
    location TEXT,
    announcement_type TEXT,
    announcement_date TEXT,
    announcement_url TEXT,
    scraped_date TEXT,
    notes TEXT,
    checked INTEGER DEFAULT 0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**Indexes:**
```sql
UNIQUE INDEX on member_id  # Prevents duplicates
INDEX on checked           # Fast filtering
INDEX on created_at        # Fast date queries
```

### Scraper (Python + Selenium)

**File:** `espaceagro_scraper.py`

**Key Methods:**
```python
- __init__()                    # Initialize with database
- _init_database()              # Create schema
- connect_to_chrome()           # Connect to debug Chrome
- scrape_algeria_announcements() # Main scraping loop
- _extract_announcements()      # Parse page HTML
- _parse_listing()              # Extract announcement data
- _announcement_exists()        # Check for duplicates
- _save_to_database()           # Insert new record
```

**Process:**
```python
1. Connect to Chrome (port 9222)
2. For each page (1 to max_pages):
   a. Navigate to URL
   b. Wait for page load
   c. Parse HTML with BeautifulSoup
   d. Extract announcements
   e. For each announcement:
      - Check if exists (by member_id)
      - If new, save to database
      - If exists, skip
   f. Random delay (3-6 seconds)
3. Close connection
```

## Technology Stack

### Frontend
- **Framework:** Next.js 15
- **Language:** TypeScript
- **Styling:** Tailwind CSS
- **HTTP Client:** Fetch API
- **Port:** 3000

### Backend
- **Framework:** Flask 3.0
- **Language:** Python 3.x
- **CORS:** Flask-CORS
- **Threading:** Python threading
- **Port:** 5000

### Database
- **Engine:** SQLite 3
- **ORM:** None (raw SQL)
- **File:** espaceagro.db
- **Size:** ~1MB per 1000 records

### Scraper
- **Browser:** Chrome (debug mode)
- **Automation:** Selenium WebDriver
- **Parser:** BeautifulSoup4
- **Protocol:** Chrome DevTools Protocol
- **Port:** 9222

## Deployment Options

### Development (Current)
```
Frontend: npm run dev (localhost:3000)
Backend:  python api.py (localhost:5000)
Database: SQLite file
Chrome:   Local debug mode
```

### Production Option 1 (Simple)
```
Frontend: Vercel (free)
Backend:  Railway/Render (free tier)
Database: PostgreSQL (Railway/Render)
Chrome:   Not needed (use Playwright)
```

### Production Option 2 (Advanced)
```
Frontend: AWS Amplify / Netlify
Backend:  AWS Lambda / Google Cloud Run
Database: AWS RDS / Google Cloud SQL
Chrome:   AWS Lambda with Chromium layer
```

### Production Option 3 (Self-hosted)
```
Frontend: Nginx + PM2
Backend:  Gunicorn + Nginx
Database: PostgreSQL
Chrome:   Headless Chrome
All:      Docker containers
```

## Security Considerations

### Current (Development)
- âš ï¸ No authentication
- âš ï¸ CORS open to all
- âš ï¸ No rate limiting
- âš ï¸ No encryption
- âš ï¸ SQLite (single user)

### Production Recommendations
- âœ… Add JWT authentication
- âœ… Restrict CORS to frontend domain
- âœ… Add rate limiting (Flask-Limiter)
- âœ… Use HTTPS everywhere
- âœ… Migrate to PostgreSQL
- âœ… Add API keys
- âœ… Validate all inputs
- âœ… Add logging/monitoring

## Performance

### Current Capacity
- **Scraping:** ~400 announcements per session
- **Database:** Can handle 100,000+ records
- **Frontend:** Renders 500+ rows smoothly
- **API:** ~100 requests/second

### Bottlenecks
1. **Scraping speed:** Limited by page load time
2. **SQLite:** Single writer at a time
3. **Frontend:** Large tables may slow down

### Optimizations
1. **Pagination:** Add pagination to table
2. **Caching:** Cache stats in Redis
3. **Indexing:** Add database indexes
4. **Lazy loading:** Load table rows on scroll
5. **PostgreSQL:** For concurrent writes

## Monitoring

### Logs
- **Frontend:** Browser console
- **Backend:** Terminal output
- **Scraper:** Terminal output
- **Database:** No logs (SQLite)

### Metrics to Track
- Scraping success rate
- New announcements per day
- API response times
- Database size
- Error rates

### Recommended Tools
- **Sentry:** Error tracking
- **LogRocket:** Frontend monitoring
- **Prometheus:** Metrics collection
- **Grafana:** Dashboards

---

**Architecture designed for simplicity and efficiency!** ğŸ—ï¸
